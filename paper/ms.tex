\documentclass{article}
\usepackage{amsmath, amssymb, mathtools, bm}
\usepackage{graphicx, graphics}
\usepackage{array}
\usepackage{geometry}
\geometry{lmargin=3cm, tmargin=3cm, bmargin=2cm, rmargin=2cm}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{\texttt{lightkurve}: Open source Python data analysis for NASA's Kepler, K2, and TESS missions}
\author{\texttt{lightkurve} and PyKE Contributors}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

\section{Lightcurve Basics}
    \subsection{The \texttt{LightCurve} class}
        A \texttt{LightCurve} object can be instantiated by passing a \texttt{time}
        array, a \texttt{flux} array, and optionally a \texttt{flux\_err} array which
        accounts for uncertainties in the \texttt{flux} measurements, i.e.,
        \begin{verbatim}
        from lightkurve.lightcurve import LightCurve
        lc = LightCurve(time, flux)
        \end{verbatim}

        \texttt{LightCurve} object provides methods described in
        Table~(\ref{tab:methods})

        \begin{table}[!htb]
            \centering
            \caption{A subset of methods provided by the \texttt{LightCurve} class}
            \begin{tabular}{cp{12cm}}
                \hline
                \textbf{Method signature} & \textbf{Short description} \\
                \hline
                \texttt{stitch} & appends the attributes \texttt{flux},
                \texttt{time}, and \texttt{flux\_err} of other given
                \texttt{LighCurve} objects.\\
                \texttt{flatten} & applies a Savitzky-Golay filter to capture
                low frequency flux variations which can be then removed in order
                to aid transit detection algorithms.\\
                \texttt{fold} & folds a lightcurve at a given period and phase.\\
                \texttt{bin} &  bins a lightcurve using a block mean or median.\\
                \texttt{cdpp} &  computes the Combined Differential Photometric
                Precision (CDPP) metric, which is a proxy for the amount of
                scatter in the lightcurve signal. \\
                \texttt{plot} & displays a lightcurve.
            \end{tabular}
            \label{tab:methods}
        \end{table}

       The \texttt{KeplerLightCurve} class extends \texttt{LightCurve} by
       adding attributes to store metadata information such as channel number,
       quality flags, campaign or quarter number, kepler id, etc.

       Additionally, \texttt{KeplerLightCurve} can be corrected for motion-dependent
       correlated noise using the \texttt{correct} method which will be discussed in
       Section~\ref{subsection:motion}.

   \subsection{The \texttt{KeplerLightCurveFile} class}
        The \texttt{KeplerLightCurveFile} class defines a structure to deal
        with lightcurve files from both NASA's Kepler and K2 missions.

        To instantiate a \texttt{KeplerLightCurveFile} object, it is necessary
        to pass a \texttt{path} which represents the address (url or local path)
        of a lightcurve file in the fits (or compressed) format, and a
        \texttt{quality\_bitmask} string which specifies quality
        flags of cadences that should be ignored.

        One crucial method of the \texttt{KeplerLightCurveFile} class is
        \texttt{get\_lightcurve} which returns a \texttt{KeplerLightCurve} object
        with the metadata provided by the corresponding \texttt{KeplerLightCurveFile}.

        Therefore, one can, for example, perform the following series of operations
        in order to fold a lightcurve from the MAST archive
\begin{verbatim}
>>> lc_file = KeplerLightCurveFile("https://archive.stsci.edu/missions/kepler/"
... "lightcurves/0119/011904151/kplr011904151-2009350155506_llc.fits")
>>> klc = lc_file.get_lightcurve("PDCSAP_FLUX").fold(period=0.837495)
>>> klc.plot()
\end{verbatim}
        \begin{figure}[!htb]
            \centering
            \includegraphics[scale=.5]{figs/fold-lc.pdf}
            \caption{Folded lightcurve of target \texttt{KIC011904151} quarter 3, showing the
            transit signal of Kepler-10b.}
            \label{fig:fold-method}
        \end{figure}

\section{Target Pixel File Basics}
    \subsection{The \texttt{KeplerTargetPixelFile} class}
        A \texttt{KeplerTargetPixelFile} object can be instantiated
        by passing a \texttt{path} (URL or local) of a target pixel file.
        Optionally, the user the select to throw away frames that contain
        a specific flag by using the \texttt{quality\_bitmask} argument.

        \texttt{KeplerTargetPixelFile} offers a number of methods
        that range from getting raw aperture photometry lightcurves to
        data visualization.

        For instance, the method \texttt{plot} can be used to visualize a
        given frame, which are depicted in Fig.~\ref{fig:plot-method}.
\begin{verbatim}
>>> import numpy as np
>>> from lightkurve import KeplerTargetPixelFile
>>> tpf = KeplerTargetPixelFile('kplr008462852-2011073133259_lpd-targ.fits.gz')
>>> tpf.plot()
>>> tpf.plot(aperture_mask=tpf.flux[0] > np.nanmean(tpf.flux[0]))
\end{verbatim}

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=.4]{figs/tpf-plot.pdf}
    \includegraphics[scale=.4]{figs/tpf-plot-aperture.pdf}
    \caption{Displaying a given frame of a TPF using \texttt{plot}.
    Optionally, an \texttt{aperture\_mask} can be passed which is
    highlighted on the right hand side.}
    \label{fig:plot-method}
\end{figure}

\section{Tools}

\subsection{Cotrending basis vectors}

Cotrending basis vectors (CBVs) correction consists in removing global correlated
systematics that occurs in a given channel [add reference]. The procedure of
designing the CBVs is discussed in [add reference].

Briefly, given a set of $n$ CBVs, one is interested in finding a vector of $n$
coefficients $\bm{\theta}=(\theta_1, \theta_2, ..., \theta_n)$ which minimizes
some cost function between the SAP flux and the set of CBVs. The mathematical
structure of the cost function is a direct consequence of the statistical
assumptions made for data.

For instance, if one assumes that the data comes from an independent and
identically distributed (iid) multivariate Gaussian distribution with mean
$\sum_{j=1}^{n}\theta_j v_{j}(t)$ and known variance $\sigma^2$, then the
cost function can be expressed as follows
\begin{align}
    \mathcal{C}(\bm{\theta}, f_{SAP}) = \sum_{t}\left(f_{SAP}(t)
    - \sum_{j=1}^{n}\theta_j v_{j}(t)\right)^2,
\label{eq:chi-square}
\end{align}
in which $f_{SAP}$ is the SAP flux and $v_j$ is the $j$-th CBV.

The maximum likelihood estimator for $\bm{\theta}$, $\bm{\theta^{*}}$ can be
expressed as
\begin{align}
    \bm{\theta}^{*} = \argmin_{\bm{\theta} \in \Theta}
    \mathcal{C}(\bm{\theta}, f_{SAP}).
\end{align}

However,~(\ref{eq:chi-square} is known to be sensitive to outliers [add reference],
therefore, as a default behaviour in \texttt{lightkurve}, we use the following cost
function
\begin{align}
    \mathcal{C}(\bm{\theta}, f_SAP) = \sum_{t} \left\rvert f_{SAP}(t)
    - \sum_{j=1}^{n}\theta_j v_{j}(t)\right\rvert,
\label{eq:l1-norm}
\end{align}


Then, the cbv-corrected flux can be computed as
\begin{equation}
    f_{CBV} = f_{SAP} - \sum_{j=1}^{n}\theta^{*}_j v_{j}(t).
\end{equation}

A runnable example of SAP flux correction for target \texttt{KOI 8462852}
(Tabby's star) can be written as follows
\begin{verbatim}
>>> from lightkurve.lightcurve import KeplerCBVCorrector
>>> cbv = KeplerCBVCorrector("https://archive.stsci.edu/missions/kepler/lightcurves/"
    ...                          "0084/008462852/kplr008462852-2011073133259_llc.fits")
>>> cbv_lc = cbv.correct(cbvs=[1,2])
\end{verbatim}
Fig~\ref{fig:cbv-correction} illustrates the correction.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=.5]{figs/cbv.pdf}
    \caption{CBV correction applied on \texttt{KOI 8462852}}
    \label{fig:cbv-correction}
\end{figure}

In the same fashion, we can apply cotrending basis vector correction to
$\mathcal{K}\mathit{2}$ lightcurves.

As an example, Fig.~\ref{fig:cbv-correction-k2} illustrates the result after
estimating the first nine coefficients for CBV correciton on target
\texttt{EPIC 201543306}.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=.5]{figs/cbv-k2.pdf}
    \caption{CBV correction applied on \texttt{EPIC 201543306}.}
    \label{fig:cbv-correction-k2}
\end{figure}

\subsubsection{Number of CBVs}
The number of CBVs will directly contribute to overfitting effects. One
way to identify a reasonable number of CBVs is to perform a grid search
as suggested in Fig~(\ref{fig:cbv-grid-search}), which shows the cost
function as a function of the number of CBVs. Usually, as the number of
CBVs increases, the value of the cost function decreases. And therefore,
the user should empirically choose a number of CBVs which does not
remove the astrophysical signal of interest [add reference].
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=.5]{figs/cbv-grid-search.pdf}
    \caption{Grid search on the number of CBVs}
    \label{fig:cbv-grid-search}
\end{figure}

An objective way of selecting the number of CBVs is to use Bayes' factors
[add reference]. In the Bayes' factor setting, the selected number of
CBVs is the one that provide the least gain in posterior probability, i.e.,
for all ordered pairs of CBVs, the Bayes factor selects $n^{*}$ number of CBVs
as follows
\begin{align}
    n^{*} = \argmin_{n} $\dfrac{p_{n+1}}{p_n}$,
\end{align}
in which $p_n$ is the posterior probability evaluated at the Maximum A Posteriori
Estimator (MAP) obtained using $n$ CBVs.

A Laplacian prior with zero mean and variance $16$ is the default prior
density over the CBVs coefficients.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=.5]{figs/cbv-bayes-factor.pdf}
    \caption{Bayes factors as a function of the number of CBVs for \texttt{EPIC 201543306}}
    \label{fig:cbv-grid-search}
\end{figure}


\subsection{Point spread function photometry}

lightkurve contains routines to perform PSF photometry in TPFs
which are implemented in the \texttt{psf} module.

Briefly, the PSF photometry problem that lightkurve solves can be formulated as
follows. Given an image $\bm{y}$, with $n$ pixels and $m$ stars, and a PSF model
$\lambda(\bm{\theta}) = \sum_{j=1}^{m} \lambda({\theta}_j)$,
find the best parameter vector
$\bm{\theta}^{*} = (\theta_1^{*}, \theta_2^{*}, ..., \theta_m^{*})$
that minimizes some cost (or loss) function $R(\lambda(\bm{\theta}), \bm{y})$
of assigning $\bm{\theta} = \bm{\theta}^{*}$.

A runnable code to perform PSF photometry in \texttt{EPIC 246199087}
(Trappist-1), can be written as follows:

\begin{verbatim}
>>> from lightkurve import KeplerTargetPixelFile
>>> from lightkurve.psf import PRFPhotometry, SceneModel
>>> from oktopus import UniformPrior
>>> tpf = KeplerTargetPixelFile("ktwo246199087-c12_lpd-targ.fits.gz")
>>> prf = tpf.get_prf_model()
>>> prior = UniformPrior(lb=[4e3, 990, 25, 1], ub=[2e4, 996, 30, 2e3])
>>> scene = SceneModel(prf=[prfs])
>>> phot = PRFPhotometry(scene_model=scene, prior=prior)
>>> results = phot.fit(tpf.flux + tpf.flux_bkg)
\end{verbatim}

The photometric results are stored in the $c \times 4$ matrix, where $c$ is the
number of frames (cadences).

From a probabilistic point of view, one is often interested in minimizing the
expected cost with respect to some probability distribution assigned to the data
$\bm{y}$ and to the parameter vector $\bm{\theta}$, from which the cost function
$R$ naturally arises. The default assumption on the data is that it follows
a Poisson probability distribution; whereas the probability distribution on the
parameter vector has to be assigned by the user using the $\texttt{prior}$
argument.

Another important aspect is the PSF model...

\subsection{Motion-dependent Correlated Noise}
\label{subsection:motion}

\section{Acknowledgments}
lightkurve is build on top of numerous packages that constitute the Scientific Python
stack, more precisely, \texttt{numpy}, \texttt{scipy}, \texttt{matplotlib}, and
\texttt{astropy}.

\end{document}
