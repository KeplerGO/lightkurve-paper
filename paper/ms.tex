%%
%% Beginning of file 'sample62.tex'
%%
%% Modified 2018 January
%%
%% This is a sample manuscript marked up using the
%% AASTeX v6.2 LaTeX 2e macros.
%%
%% AASTeX is now based on Alexey Vikhlinin's emulateapj.cls
%% (Copyright 2000-2015).  See the classfile for details.

%% AASTeX requires revtex4-1.cls (http://publish.aps.org/revtex4/) and
%% other external packages (latexsym, graphicx, amssymb, longtable, and epsf).
%% All of these external packages should already be present in the modern TeX
%% distributions.  If not they can also be obtained at www.ctan.org.

%% The first piece of markup in an AASTeX v6.x document is the \documentclass
%% command. LaTeX will ignore any data that comes before this command. The
%% documentclass can take an optional argument to modify the output style.
%% The command below calls the preprint style  which will produce a tightly
%% typeset, one-column, single-spaced document.  It is the default and thus
%% does not need to be explicitly stated.
%%
%%
%% using aastex version 6.2
\documentclass[twocolumn]{aastex62}
\usepackage{amsmath, amssymb, mathtools, bm}
\usepackage{color}

\usepackage[cache=false]{minted}

\newcommand{\ktwo}{{\it K$\mathit{2}$}}
\newcommand{\tess}{{\it TESS}}
\newcommand{\kepler}{{\it Kepler}}
\newcommand{\lightkurve}{\texttt{lightkurve}}
\newcommand{\LightCurve}{\texttt{LightCurve}}
\newcommand{\KeplerLightCurve}{\texttt{KeplerLightCurve}}
\newcommand{\numpy}{\texttt{numpy}}
\newcommand{\code}{\texttt}
\newcommand{\clh}[1]{\textcolor{red}{ \textbf{***CLH: #1 ***}}}
\newcommand{\ze}[1]{\textcolor{blue}{ \textbf{***CLH: #1 ***}}}
\newcommand{\gb}[1]{\textcolor{green}{ \textbf{***CLH: #1 ***}}}



\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}

\received{January 1, 2018}
\revised{January 7, 2018}
\accepted{\today}
\submitjournal{ApJ}

\begin{document}

\title{\lightkurve: an open source Python package for NASA's \kepler, \ktwo~ and \tess~ data analysis}

\correspondingauthor{Geert Barentsen}
\email{hello@geert.io}

\author{\lightkurve~contributors}
\affil{The galatic startup}

\author{Jos\'e Vin\'icius de Miranda Cardoso}
\affiliation{Bay Area Environmental Research Institute \\
Petaluma \\
California, USA}
\collaboration{(AAS Journals Data Scientists collaboration)}

\begin{abstract}
\clh{Key messages are: WHY do users need to create their own products? (RB, asteroids, variable apertures, crowding etcetc). WHAT are we providing? (lightkurve, easy Kepler/K2/TESS access). HOW can they use it? (Beautiful examples). Plots:
  \begin{itemize}
  \item{Beautiful TPF and masking}
  \item{Beautiful flattening?}
  \item{Beautiful motion detrending}
  \item{Beautiful CBV correction}
  \item{Beautiful planet finding}
  \end{itemize}
}



  The Kepler/K2 mission has provided the astronomy community with light curves of more than 400,000 objects. These ready-made light curves have allowed the community to quickly investigate targets. However, light curves built by the Kepler pipeline have built-in, fixed assumptions, such as aperture choice and background correction. These assumption are valid for the majority of targets, but for certain science cases a bespoke analysis may be needed. Performing custom photometry with the raw Kepler data has many benefits. Working with the raw data allows users to mitigate systematics for their particular science case, (such as the Kepler Rolling band) and verify the aperture selected by the pipeline. Working directly with the pixel data allows users to check for cosmic rays or stray asteroids in the target aperture.

 We present \lightkurve~, an open source package for analysis of flux time series pixel using Python. \lightkurve~ is designed to interface seemlessly with data from NASA's \kepler, \ktwo~ and \tess~ missions. It is a multipurpose, general tool to make producing time-series photometry from raw pixel data easier and more reproducible between different teams. Using \lightkurve~ tools it is simple to create corrected time-series photometry from raw pixel data from any of these missions and perform many common light curve corrections, including correcting for K2 motion using the SFF method. \lightkurve~ is open source, modable and provides an excellent learning tool for any users wanting to get to started with Kepler data.

\end{abstract}

\keywords{}

\section{Introduction} \label{sec:intro}

\paragraph{What is the background}
\begin{itemize}
\item{Time series photometry is available for a wide variety of astrophysical purposes and in a wide variety of formats.}
\item{This ranges from 30 year long time series of variable stars\cite{citationneeded} to short time-series of hours for X-Ray objects \cite{citationneeded}}
\item{In particular, NASA's \kepler and \ktwo missions have provided some of the most precise, long term monitoring of stars to date \cite{citationneeded}.}
\item{In the near future the \tess mission will delivering high-precision time series data for 90\% of the sky, providing light curves for X millions of object \cite{citationneeded}.}
\item{\clh{What are the challenges we face in time-series astronomy?}}
\end{itemize}

\paragraph{What tools are currently available?}
\begin{itemize}
\item PyKE
\item \clh{Geert says he can do this para}
\item However, no one package provide a simple, open source framework for manipulating time-series data that is general purpose.
\end{itemize}

\paragraph{What are we presenting}
\begin{itemize}
\item{We present \lightkurve as a general tool to use almost all time-series photometry, with a particular focus on \kepler, \ktwo~ and \tess.}
\item While these missions have powerful pipelines which deliver high-precision light curves for many objects (citation), \lightkurve allows bespoke analyses tailored for specific science cases.
\item These might include custom aperture photometry, PSF photometry in crowded field and studies of long period transient events such as supernovae and AGN.
\item \lightkurve~ is not designed to replace NASA pipelines, but to allow users more flexibility when producing time-series for their unique science cases.
\item{We have designed \lightkurve as a tool process this vast wealth of data easily and intuitively with many features and tools to remove reduce the overhead in using this data.}
\item By using these tools users have the advantage of easy reproducibility. By sharing the same tools and the same short scripts for producing their light curve products different teams will be more able to compare results.
\end{itemize}

\paragraph{How do you use lightkurve}
\begin{itemize}
\item designed to be flexible
\item nuts and bolts
\item open source
\item easy data fetching
\item easy api
\end{itemize}

\paragraph{What is the selling point of lightkurve}
\begin{itemize}
\item There are two sides to the \lightkurve package. Firstly, \lightkurve can be used as an extraction package for creating time-series photometry from astronomical images such as \kepler Target Pixel Files (TPFs) or \tess Full Frame Images (FFIs). This includes simple aperture photometry, PSF photometry and centroiding.
\item Secondly, \lightkurve can be used for analysis of time-series photometry. This includes motion detrending, CBV corrections, outlier rejection and period folding.
\item Together these two sides can be combined to convert raw data from \kepler, \ktwo~ and \tess~ to cleaned light curves of exoplanet candidates, supernovae and extra-galactic objects.
\item One flexible system for all optical photometry
\item Learning/teaching tool
\end{itemize}

\paragraph{Future resources?}
\begin{itemize}
\item This is \lightkurve 1.0
\item Anticipate adding new features
\item Easily extendible for users to add in new features
\item{There are already tutorials, which will be expanded}
\end{itemize}

\paragraph{What's in this paper?}
\begin{itemize}
\item In this paper we discuss the basic components of \lightkurve
\item We will show three key components of analysis with \lightkurve; manipulating lightcurves, creating lightcurves,
and removing systematics from lightcurves.
\item \lightkurve has a full compliment of tutorials
\item More details can be found in our documentation at link.
\end{itemize}



\section{Package overview}


\clh{Ze can you do a beautiful diagram here?}

\subsection{The \LightCurve~and \KeplerLightCurve~classes}
The \LightCurve~class is a simple cointainer to store \numpy~arrays
(hereafter, arrays) related to flux time-domain measurements.

The \LightCurve~object provides methods to store, process, and
convert lightcurves. Table~\ref{tab:methods} contains a description
of a subset of the methods.

A \LightCurve~object can be instantiated by passing a \texttt{time}
array, a \texttt{flux} array, and, optionally, a \texttt{flux\_err} array
which accounts for uncertainties in the \texttt{flux} measurements, i.e.,
\begin{minted}{python}
>>> from lightkurve import LightCurve
>>> lc = LightCurve(time, flux)
\end{minted}

The \KeplerLightCurve class extends \LightCurve by
adding attributes to store metadata information such as channel number,
quality flags, campaign or quarter number, kepler id, etc.

Additionally, \texttt{KeplerLightCurve} can be corrected for motion-dependent
correlated noise using the \texttt{correct} method which will be discussed in
Section~\ref{subsection:motion}.

\subsection{The \texttt{KeplerLightCurveFile} class}
The \texttt{KeplerLightCurveFile} class defines a structure to deal
with lightcurve files from both NASA's Kepler and K2 missions.

To instantiate a \texttt{KeplerLightCurveFile} object, it is necessary
to pass a \texttt{path} which represents the address (url or local path)
of a lightcurve file in the fits (or compressed) format, and a
\texttt{quality\_bitmask} string which specifies quality
flags of cadences that should be ignored.

One crucial method of the \texttt{KeplerLightCurveFile} class is
\texttt{get\_lightcurve} which returns a \texttt{KeplerLightCurve} object
with the metadata provided by the corresponding \texttt{KeplerLightCurveFile}.

Therefore, one can, for example, perform the following series of operations
in order to fold a lightcurve from the MAST archive
\begin{minted}{python}
>>> lc_file = KeplerLightCurveFile("kplr011904151-2009350155506_llc.fits")
>>> klc = lc_file.PDCSAP_FLUX.fold(period=0.837495)
>>> klc.plot()
\end{minted}

\subsection{The \texttt{KeplerTargetPixelFile} class}
A \texttt{KeplerTargetPixelFile} object can be instantiated
by passing a \texttt{path} (URL or local) of a target pixel file.
Optionally, the user can elect to throw away frames that contain
a specific flag by using the \texttt{quality\_bitmask} argument.

\texttt{KeplerTargetPixelFile} offers a number of methods
that range from getting raw aperture photometry lightcurves to
data visualization.

For instance, the method \texttt{plot} can be used to visualize a
given frame, which are depicted in Fig.~\ref{fig:plot-method}.

\begin{verbatim}
>>> import numpy as np
>>> from lightkurve import KeplerTargetPixelFile
>>> tpf = KeplerTargetPixelFile("kplr008462852-2011073133259_lpd-targ.fits")
>>> tpf.plot()
>>> tpf.plot(aperture_mask=tpf.flux[0] > np.nanmean(tpf.flux[0]))
\end{verbatim}

\begin{figure}[!htb]
    \centering
    \plotone{figs/tpf-plot.pdf}
    \plotone{figs/tpf-plot-aperture.pdf}
    \caption{Displaying a given frame of a TPF using \texttt{plot}.
    Optionally, an \texttt{aperture\_mask} can be passed which is
    highlighted on the right hand side.}
    \label{fig:plot-method}
\end{figure}

In an image with $n$ pixels, where the flux and the center positions of the
$i$-th pixel are denoted as $f_i$ and $(x_i, y_i)$, respectively, the centroids
may be expressed as
\begin{align}
    x^{\star} = \dfrac{\sum_{i=1}^{n} f_i x_i}{\sum_{i=1}^{n}f_i},
    ~~y^{\star} = \dfrac{\sum_{i=1}^{n} f_i y_i}{\sum_{i=1}^{n}f_i}.
\end{align}

In \texttt{lightkurve}, the centroids in every cadence can be computed as
\begin{verbatim}
>>> from lightkurve import KeplerTargetPixelFile
>>> tpf = KeplerTargetPixelFile('ktwo246199087-c12_lpd-targ.fits.gz')
>>> x_star, y_star = tpf.get_centroids()
\end{verbatim}


\clh{This table I believe needs a little updating? There can also be a second table for TPF}
\begin{table}[!htb]
    \centering
    \caption{A subset of methods provided by the \LightCurve~class}
    \begin{tabular}{cp{6.5cm}}
        \hline
        \textbf{Method} & \textbf{Short description} \\
        \hline
        \texttt{stitch} & appends the attributes \texttt{flux},
        \texttt{time}, and \texttt{flux\_err} of other given
        \texttt{LighCurve} objects.\\
        \texttt{flatten} & applies a Savitzky-Golay filter to capture
        low frequency flux variations which can be then removed in order
        to aid transit detection algorithms.\\
        \texttt{fold} & folds a lightcurve at a given period and phase.\\
        \texttt{bin} &  bins a lightcurve using a block mean or median.\\
        \texttt{cdpp} &  computes the Combined Differential Photometric
        Precision (CDPP) metric, which is a proxy for the amount of
        scatter in the lightcurve signal. \\
        \texttt{plot} & displays a lightcurve.
    \end{tabular}
    \label{tab:methods}
\end{table}

%This might belong somewhere else, but it's slowing down our introduction
\subsection{PyKE Tools}
\begin{itemize}
\item previously there was pyke, don't spend too long on this
\item pyke is still available
\item \lightkurve uses only python
\item  new Python package which makes the custom analysis of target easy.  Based on AstroPy (cite Astropy).
\end{itemize}


\section{Common Use Cases}

\subsection{Creating Custom Light Curves}

    \subsubsection{Simple Aperture Photometry (SAP)}
    \begin{itemize}
        \item What is SAP?
        \item Why do SAP?s
        \item How do you do SAP?
    \end{itemize}

    \subsubsection{Point Spread Function (PSF) Photometry}
        %What is PSF?
        Point Spread Function (PSF) photometry is the de facto technique to
        process crowded-field images~\cite{stetson1987, heasley1999}. In context of Kepler
        and K2 missions, Libralato \textit{et al}~\cite{libralato2016} have shown...

        See a detailed explaination of PSF photometry in \ref{appendix:psf}
        %Why do PSF?
        The underlying principle of PSF photometry consists in modelling a given crowded
        image as a linear combination of individual PSFs and possibly a background model.
        On the PSF model itself, it is commonly assumed that the flux
        at an arbitrary pixel position increases linearly with the integrated
        flux~\cite{stetson1987, heasley1999}.

        %How do you do PSF?
        \lightkurve ~contains routines to perform PSF photometry in TPFs
        which are implemented in the \texttt{psf} module.

        The example below illustrates PSF photometry on the target \texttt{EPIC 246199087}
        (Trappist-1):

        \clh{If you want to include oktopus in this snippet you have to explain what it is to the reader:)}
        \begin{verbatim}
        >>> from lightkurve import KeplerTargetPixelFile
        >>> from lightkurve.psf import PRFPhotometry, SceneModel
        >>> from oktopus import UniformPrior
        >>> tpf = KeplerTargetPixelFile("ktwo246199087-c12_lpd-targ.fits.gz")
        >>> prf = tpf.get_prf_model()
        >>> prior = UniformPrior(lb=[4e3, 990, 25, 1], ub=[2e4, 996, 30, 2e3])
        >>> scene = SceneModel(prf=[prfs])
        >>> phot = PRFPhotometry(scene_model=scene, prior=prior)
        >>> results = phot.fit(tpf.flux + tpf.flux_bkg)
        \end{verbatim}

        The photometric results are stored in a $c \times 4$ matrix, where $c$ is the
        number of frames (cadences).

\subsection{Correcting Common Systematics}

    We provide tools to correct for two systematics that are common between targets on the same channel.
    We provide corrections using \emph{Cotrending Basis Vectors} (CBVs) which mitigate systematics due to e.g. spacecraft heating. (See Appendix \ref{appendix:CBV} for a detailed explanation of CBVs)
    We also provide a simple implementation of the \emph{Self Flat Fielding} (SFF) method to correct for spacecraft motion. (See Appendix \ref{appendix:motion} for a detailed explanation of SFF)

    We only intend to provide simple tools.
    Ideally, systematics are removed simultaneously with fitting a model (e.g. Montet and DFM 2015).


    \subsubsection{Correcting Spacecraft Motion using Lightkurve}
        Spacecraft-induced correlated noise remains one of the greatest hurdles to
        analyzing K2 lightcurves. Many algorithms have been developed to mitigate
        motion-dependent artifacts~\cite{vanderburg14}[CITE K2SC and EVEREST].
        In \lightkurve, we implement an algorithm based off of the self-flat-field
        (SFF) presented in~\cite{vanderburg14}.

        SFF works by decorrelating the simple aperture flux
        against the information on the spacecraft motion, obtained by computing the
        arclength using the centroids of the target. (See Appendix \ref{appendix:motion} for a detailed explanation of SFF)

        \begin{verbatim}
        from lightkurve import KeplerTargetPixelFile
        tpf = KeplerTargetPixelFile("ktwo248667471-c14_lpd-targ.fits.gz")
        lc = tpf.to_lightcurve()
        centroids = tpf.get_centroids()
        lcc = lc.correct(centroids[0], centroids[1])
        \end{verbatim}


    \subsubsection{Correcting Common Systematics with CBVs using Lightkurve}

        \clh{Simple paragraph describing CBVs}
        Cotrending basis vectors (CBVs) can remove global correlated
        systematics present in a given channel \cite{smith2012}.

        An example of SAP flux correction for target \texttt{KOI 8462852}
        (Tabby's star) can be written as follows
        \begin{verbatim}
        >>> from lightkurve.lightcurve import KeplerCBVCorrector
        >>> cbv = KeplerCBVCorrector("kplr008462852-2011073133259_llc.fits")
        >>> cbv_lc = cbv.correct(cbvs=[1,2])
        \end{verbatim}

        Fig~\ref{fig:cbv-correction} illustrates the correction. The pink line has a shift from
        the green line because in \lightkurve~we do not account the flux lost outside of the aperture mask.

        \begin{figure}[!htb]
            \centering
            \plotone{figs/cbv.pdf}
            \caption{CBV correction applied on \texttt{KOI 8462852}
            \clh{This is great, really valuable plot. I would just change to have two lines with labels corrected and uncorrected.}}
            \label{fig:cbv-correction}
        \end{figure}


        Improperly tuning the number of CBVs can cause over-/under-fitting. One
        way to identify a reasonable number of CBVs is to perform a grid search
        as shown in Fig~(\ref{fig:cbv-grid-search}). The selection of the number of CBVs is set by inspecting the
        grid search curve can be set through model comparison heuristics like AIC, BIC,
        or cross-validation \cite{ivezi2014}.

        In the same fashion, we can apply cotrending basis vector correction to
        \ktwo lightcurves.


\subsection{Recovering a planet signal}




\section{Example Code Snippets}

\subsection{Recover a Planet in 5 lines}
\begin{figure}
\plotone{figs/fold-lc.pdf}
\caption{Folded lightcurve of target \texttt{KIC011904151} quarter 3, showing the
            transit signal of Kepler-10b.
\label{fig:fold-method}}
\end{figure}




\section{Future work}

Explain PSF photometry needs users and data-driven model capability.

We do not intend to implement transit fitting, more advanced detrending, etc.
Instead, lightkurve intends to provide the building blocks needed to build
or interact with such packages.

We intend to add many tutorials.

Explain how people can contribute.


\section{Conclusions}

we will discuss => we have discussed






\appendix
\section{Cotrending basis vectors}
\label{appendix:cbvs}

Given a set of $n$ CBVs, one is interested in finding a vector of $n$
coefficients $\bm{\theta}=(\theta_1, \theta_2, ..., \theta_n)$ which minimizes
some cost function between the SAP flux and the set of CBVs. The mathematical
structure of the cost function is a direct consequence of the statistical
assumptions made for data.

For instance, if one assumes that the data comes from an independent and
identically distributed (iid) multivariate Gaussian distribution with mean
$\sum_{j=1}^{n}\theta_j v_{j}(t)$ and known variance $\sigma^2$, then the
cost function can be expressed as follows
\begin{align}
    \mathcal{C}(\bm{\theta}, f_{SAP}) = \sum_{t}\left(f_{SAP}(t)
    - \sum_{j=1}^{n}\theta_j v_{j}(t)\right)^2,
\label{eq:chi-square}
\end{align}
in which $f_{SAP}$ is the SAP flux and $v_j$ is the $j$-th CBV.

The maximum likelihood estimator for $\bm{\theta}$, $\bm{\theta^{\star}}$ can be
expressed as
\begin{align}
    \bm{\theta}^{\star} = \argmin_{\bm{\theta} \in \Theta} \mathcal{C}(\bm{\theta}, f_{SAP}).
\end{align}

However, Equation~(\ref{eq:chi-square}) is sensitive to outliers~\cite{ivezi2014},
therefore, as a default behaviour in \lightkurve, we use the following cost
function
\begin{align}
    \mathcal{C}(\bm{\theta}, f_SAP) = \sum_{t} \left\rvert f_{SAP}(t)
    - \sum_{j=1}^{n}\theta_j v_{j}(t)\right\rvert.
\label{eq:l1-norm}
\end{align}


Then, the CBV-corrected flux can be computed as
\begin{equation}
    f_{CBV} = f_{SAP} - \sum_{j=1}^{n}\theta^{\star}_j v_{j}(t).
\end{equation}


%I think this para will be moved in later versions, we don't need this figure,
The number of CBVs will directly contribute to overfitting effects. One
way to identify a reasonable number of CBVs is to perform a grid search
as suggested in Fig~(\ref{fig:cbv-grid-search}), which shows the cost
function as a function of the number of CBVs. Usually, as the number of
CBVs increases, the value of the cost function decreases. And therefore,
the user should empirically choose a number of CBVs which does not
remove the astrophysical signal of interest [add reference].


% MGS note: Wait--- won't the cost function decrease monotonically for CBVs?
% Do you use AIC or BIC or cross-validation?

%CLH: This is a little detailed for this paper, I might consider just leaving it as ``we use BIC''
An objective way of selecting the number of CBVs is to use Bayes' factors
[add reference]. In the Bayes' factor setting, the selected number of
CBVs is the one that provide the least gain in posterior probability, i.e.,
for all ordered pairs of CBVs, the Bayes factor selects $n^{\star}$ number of CBVs
as follows
\begin{align}
    n^{\star} = \argmin_{n} \dfrac{p_{n+1}}{p_n},
\end{align}
in which $p_n$ is the posterior probability evaluated at the Maximum A Posteriori
Estimator (MAP) obtained using $n$ CBVs.

A Laplacian prior with zero mean and variance $16$ is the default prior
density over the CBVs coefficients.

\section{Point spread function photometry}
\label{appendix:psf}

Briefly, the PSF photometry problem that \lightkurve~solves can be formulated as
follows. Given an image $\bm{y}$, with $n$ pixels and $m$ stars, and a PSF model
$\lambda(\bm{\theta}) = \sum_{j=1}^{m} \lambda({\theta}_j)$,
find the best parameter vector (which encodes fluxes and center positions for $m$
stars) $\bm{\theta}^{\star} = (\theta_1^{\star}, \theta_2^{\star}, ..., \theta_m^{\star})$
that minimizes some cost (or loss) function $R(\lambda(\bm{\theta}), \bm{y})$
of assigning $\bm{\theta} = \bm{\theta}^{\star}$.

From a probabilistic point of view, one is often interested in minimizing the
expected cost with respect to some probability distribution assigned to the data
$\bm{y}$ and to the parameter vector $\bm{\theta}$, from which the cost function
$R$ naturally arises. The default assumption, made in \lightkurve,~on the data is
that it follows a Poisson probability distribution, whereas the probability
distribution on the parameter vector has to be assigned by the user using the $\texttt{prior}$
argument. Using a uniform prior for $\bm{\theta}$, the MAP estimator can be written
as
\begin{align}
    \bm{\theta}^{\star}(\bm{y}) = \argmin_{\bm{\theta} \in \Lambda} \sum_{i=1}^{n}
    \left(\sum_{j=1}^{m}\lambda_i(\bm{\theta}_j) - y_i\log\sum_{j=1}^{m}\lambda_i(\bm{\theta}_j)\right),
\end{align}
in which $\Lambda$ is the support of $\bm{\theta}$.

Another important aspect is the PSF model...

\section{Motion-dependent Correlated Noise}
\label{appendix:motion}

\clh{Quick discussion of the SFF algorithm}
\acknowledgments

We would like to express our gratitude...
Funding sources

\vspace{5mm}
\facilities{Kepler}

\software{astropy}


\bibliographystyle{aasjournal}
\bibliography{ms}

\end{document}
